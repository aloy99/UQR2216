{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 580 rows.\n",
      "\n",
      "Imported dataset:\n",
      "    Year  Month  Days    Type  Occupancy Rate   Room Rate  Room Receipt\n",
      "0  2020      1    31  Luxury       83.478003  506.427381    422.755465\n",
      "1  2019     12    31  Luxury       86.472915  493.608149    426.837353\n",
      "2  2019     11    30  Luxury       89.676464  452.747203    406.007682\n"
     ]
    }
   ],
   "source": [
    "hotel = pd.read_excel('Singapore_Hotel.xlsx', comment='#')\n",
    "#reading excel file, with the exception of rows commented with #\n",
    "#for my installation of jupyter notebook, the excel file was located in the default folder we were instructed to direct our installation at, Documents/0_py\n",
    "\n",
    "print('Dataset has', len(hotel), 'rows.\\n')\n",
    "print('Imported dataset:\\n', hotel.head(3))\n",
    "#checking if data set has been loaded correctly\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: Days, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "hotel = pd.DataFrame(hotel)\n",
    "hotel.head()\n",
    "hotel.loc[(hotel.Days == -4383),'Days']=31\n",
    "test = hotel.loc[hotel.Days == -4383,'Days']\n",
    "#removing invalid data entries for Days, replacing with 31 as they all occur where Month = 1\n",
    "print(test.head())\n",
    "#verifying that invalid data entries for Days have been successfully removed\n",
    "\n",
    "hotel[\"Year\"] = hotel[\"Year\"].astype(\"category\")\n",
    "hotel[\"Month\"] = hotel[\"Month\"].astype(\"category\")\n",
    "hotel[\"Days\"] = hotel[\"Days\"].astype(\"category\")\n",
    "hotel[\"Type\"] = hotel[\"Type\"].astype(\"category\")\n",
    "#setting the variables Year, Month, Days and Type as category data types, such that statsmodels can interpret them directly as categorical variables without the need for pd.get_dummies\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Days</th>\n",
       "      <th>Type</th>\n",
       "      <th>occupancy_rate</th>\n",
       "      <th>room_rate</th>\n",
       "      <th>room_receipt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>83.478003</td>\n",
       "      <td>506.427381</td>\n",
       "      <td>422.755465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>86.472915</td>\n",
       "      <td>493.608149</td>\n",
       "      <td>426.837353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>89.676464</td>\n",
       "      <td>452.747203</td>\n",
       "      <td>406.007682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>87.985274</td>\n",
       "      <td>457.485963</td>\n",
       "      <td>402.520279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>88.450824</td>\n",
       "      <td>489.061425</td>\n",
       "      <td>432.578859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year Month Days    Type  occupancy_rate   room_rate  room_receipt\n",
       "0  2020     1   31  Luxury       83.478003  506.427381    422.755465\n",
       "1  2019    12   31  Luxury       86.472915  493.608149    426.837353\n",
       "2  2019    11   30  Luxury       89.676464  452.747203    406.007682\n",
       "3  2019    10   31  Luxury       87.985274  457.485963    402.520279\n",
       "4  2019     9   30  Luxury       88.450824  489.061425    432.578859"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#renaming columns to remove spaces, for compatibility with following parts\n",
    "hotel.rename(columns={'Occupancy Rate': 'occupancy_rate', 'Room Rate': 'room_rate', 'Room Receipt': 'room_receipt'},inplace=True)\n",
    "hotel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   room_receipt  Year Month Days    Type  occupancy_rate   room_rate\n",
      "0    422.755465  2020     1   31  Luxury       83.478003  506.427381\n",
      "1    426.837353  2019    12   31  Luxury       86.472915  493.608149\n",
      "2    406.007682  2019    11   30  Luxury       89.676464  452.747203\n",
      "3    402.520279  2019    10   31  Luxury       87.985274  457.485963\n",
      "4    432.578859  2019     9   30  Luxury       88.450824  489.061425\n",
      "\n",
      " room_receipt ~ occupancy_rate + room_rate + occupancy_rate_cube + occupancy_rate_cbrt + room_rate_cube + room_rate_cbrt\n",
      "\n",
      "Adjusted R2 = 0.9964955622262521 for 6 Xs.\n",
      "Variable to drop: room_rate_cube\n",
      "\n",
      "Adjusted R2 = 0.9964817520165847 for 5 Xs.\n",
      "Variable to drop: occupancy_rate_cube\n",
      "\n",
      "Adjusted R2 = 0.9964526880003438 for 4 Xs.\n",
      "Variable to drop: occupancy_rate_cbrt\n",
      "\n",
      "Adjusted R2 = 0.9962339538401873 for 3 Xs.\n",
      "Variable to drop: room_rate_cbrt\n",
      "\n",
      "Adjusted R2 = 0.9957001529524155 for 2 Xs.\n",
      "Variable to drop: occupancy_rate\n",
      "\n",
      "Adjusted R2 = 0.9815747087177957 for 1 Xs.\n",
      "Variable left: room_rate\n",
      "\n",
      "Restarting from best model (with 6 Xs) found so far...\n",
      "\n",
      "Adding 1 2-way interactions among 2 untransformed variables in best model found so far:\n",
      "occupancy_rate_x_room_rate\n",
      "\n",
      "Adjusted R2 = 1.0 for 7 Xs.\n",
      "Variable to drop: room_rate\n",
      "\n",
      "Adjusted R2 = 1.0 for 6 Xs.\n",
      "Variable to drop: occupancy_rate\n",
      "\n",
      "Adjusted R2 = 1.0 for 5 Xs.\n",
      "Variable to drop: occupancy_rate_cube\n",
      "\n",
      "Adjusted R2 = 1.0 for 4 Xs.\n",
      "Variable to drop: room_rate_cbrt\n",
      "\n",
      "Adjusted R2 = 1.0 for 3 Xs.\n",
      "Variable to drop: room_rate_cube\n",
      "\n",
      "Adjusted R2 = 1.0 for 2 Xs.\n",
      "Variable to drop: occupancy_rate_cbrt\n",
      "\n",
      "Adjusted R2 = 1.0 for 1 Xs.\n",
      "Variable left: occupancy_rate_x_room_rate\n",
      "\n",
      "Best model has 7 Xs:\n",
      "                          Results: Ordinary least squares\n",
      "====================================================================================\n",
      "Model:                    OLS                   Adj. R-squared:          1.000      \n",
      "Dependent Variable:       room_receipt          AIC:                     -26902.5539\n",
      "Date:                     2021-02-16 22:42      BIC:                     -26867.6497\n",
      "No. Observations:         580                   Log-Likelihood:          13459.     \n",
      "Df Model:                 7                     F-statistic:             2.214e+27  \n",
      "Df Residuals:             572                   Prob (F-statistic):      0.00       \n",
      "R-squared:                1.000                 Scale:                   4.1437e-22 \n",
      "------------------------------------------------------------------------------------\n",
      "                            Coef.  Std.Err.         t          P>|t|   [0.025 0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "Intercept                   0.0000   0.0000             0.0283 0.9774 -0.0000 0.0000\n",
      "occupancy_rate              0.0000   0.0000             0.0230 0.9817 -0.0000 0.0000\n",
      "room_rate                   0.0000   0.0000             0.0056 0.9956 -0.0000 0.0000\n",
      "occupancy_rate_cube        -0.0000   0.0000            -0.0210 0.9833 -0.0000 0.0000\n",
      "occupancy_rate_cbrt        -0.0000   0.0000            -0.0289 0.9770 -0.0000 0.0000\n",
      "room_rate_cube              0.0000   0.0000             0.0437 0.9652 -0.0000 0.0000\n",
      "room_rate_cbrt              0.0000   0.0000             0.0130 0.9896 -0.0000 0.0000\n",
      "occupancy_rate_x_room_rate  0.0100   0.0000 7330598727186.8623 0.0000  0.0100 0.0100\n",
      "------------------------------------------------------------------------------------\n",
      "Omnibus:                  121.834           Durbin-Watson:              0.002       \n",
      "Prob(Omnibus):            0.000             Jarque-Bera (JB):           270.288     \n",
      "Skew:                     -1.116            Prob(JB):                   0.000       \n",
      "Kurtosis:                 5.490             Condition No.:              249839076880\n",
      "====================================================================================\n",
      "* The condition number is large (2e+11). This might indicate             strong\n",
      "multicollinearity or other numerical problems.\n",
      "\n",
      "Descending order of X's significance:\n",
      "occupancy_rate_x_room_rate\n",
      "room_rate_cube\n",
      "occupancy_rate_cbrt\n",
      "occupancy_rate\n",
      "occupancy_rate_cube\n",
      "room_rate_cbrt\n",
      "room_rate\n"
     ]
    }
   ],
   "source": [
    "#code adapted from Regression_Interaction_Variable (- Collinearity).ipynb, collinearity component has been commented out as we are addressing that subsequently.\n",
    "df = hotel\n",
    "y = 'room_receipt'\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "colname = list(df)\n",
    "colname.insert(0, colname.pop(colname.index(y)))\n",
    "df = df[colname]\n",
    "print(df.head())\n",
    "\n",
    "trf = ['_cube', '_cbrt']\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "for i in list(df)[1:]:\n",
    "    try:\n",
    "        df[i + trf[0]] = df[i] ** (3. if '_cube' in trf else 2.)\n",
    "        df[i + trf[1]] = np.cbrt(df[i]) if '_cube' in trf else np.sqrt(df[i])\n",
    "    except:\n",
    "        df.drop(i, axis=1, inplace=True)\n",
    "\n",
    "df0 = df.copy()\n",
    "    \n",
    "#perform feature selection using adjusted R2\n",
    "\n",
    "modeleq = ' + '.join(list(df)).replace('+', '~', 1)\n",
    "print('\\n',modeleq)\n",
    "maxR2 = -np.inf\n",
    "bmodeleq = modeleq\n",
    "numx = df.shape[1] - 1\n",
    "x1x2 = False #interaction variables not yet included\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "while True:\n",
    "    regout = ols(modeleq, df).fit()\n",
    "    R2 = regout.rsquared_adj\n",
    "    #see if a better model is found:\n",
    "    if R2 > maxR2:\n",
    "        maxR2 = R2\n",
    "        bmodeleq = modeleq\n",
    "\n",
    "    print('\\nAdjusted R2 =', R2, 'for', numx, 'Xs.')\n",
    "\n",
    "    if numx == 1:\n",
    "        print('Variable left:', modeleq[modeleq.find('~') + 2 :])\n",
    "        if x1x2:\n",
    "            #one xvar left\n",
    "            #get out of 'while' loop:\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            #add interaction variables for original untransformed variables in best model so far\n",
    "            \n",
    "            numx = bmodeleq.count('+') + 1\n",
    "            print('\\nRestarting from best model (with', numx, 'Xs) found so far...')\n",
    "            \n",
    "            colname = bmodeleq.replace('~', '+').split(' + ')\n",
    "            df = df0[colname]\n",
    "            colname = colname[1:] #remove y\n",
    "            \n",
    "            for i in range(numx):\n",
    "                #look for 1st transformed variable:\n",
    "                if colname[i][-5:] in trf:\n",
    "                    i = i - 1\n",
    "                    #colname[i] is the last untransformed x\n",
    "                    break\n",
    "            \n",
    "            print('\\nAdding', int((i + 1) * i / 2), '2-way interactions among', i + 1,\n",
    "                  'untransformed variables in best model found so far:')\n",
    "            for j in range(i):\n",
    "                #untransformed x in colname up to [i]\n",
    "                for k in range(j + 1, i + 1):\n",
    "                    a = colname[j] + '_x_' + colname[k]\n",
    "                    print(a)\n",
    "                    df[a] = df[colname[j]] * df[colname[k]]\n",
    "                    \n",
    "            df0 = df.copy()\n",
    "                    \n",
    "            #delete any x too highly correlated with another x, to avoid collinearity\n",
    "            \n",
    "            corv = pd.DataFrame() #start empty dataframe for corr(Xs, y) to come\n",
    "            for x in list(df)[1:]:\n",
    "                #during 1st time thru loop, new column, with label, created in empty dataframe\n",
    "                corv.loc[x, y] = df[x].corr(df[y]) #new entry, with row label, added to dataframe\n",
    "                \n",
    "            corv = corv.loc[abs(corv).sort_values([y]).index, :] #corr(Xs, y) ranked\n",
    "            modeleq = ' + '.join(list(df0)).replace('+', '~', 1)\n",
    "            numx = df0.shape[1] - 1\n",
    "            x1x2 = True #interaction variables already included\n",
    "            \n",
    "            #beyond-pairwise collinearity may still be introduced with the interaction variables\n",
    "            \n",
    "            df = df0.copy() #ready for continuing deletion\n",
    "            continue\n",
    "\n",
    "    #identify X variable to delete by finding the one with smallest abs(t-stat):\n",
    "    t = regout.tvalues[1:]\n",
    "    xdrop = list(t[abs(t) == min(abs(t))].index)[0]\n",
    "    print('Variable to drop:', xdrop)\n",
    "    \n",
    "    df.drop(xdrop, axis=1, inplace=True)\n",
    "    modeleq = ' + '.join(list(df)).replace('+', '~', 1)\n",
    "    \n",
    "    numx = numx - 1\n",
    "\n",
    "print('\\nBest model has', bmodeleq.count('+') + 1, 'Xs:')\n",
    "out = ols(bmodeleq, df0).fit()\n",
    "#collinearity is still entirely possible at this stage\n",
    "print(out.summary2())\n",
    "\n",
    "print(\"\\nDescending order of X's significance:\")\n",
    "print('\\n'.join(list(abs(out.tvalues[1:]).sort_values(0, ascending=False).index)))\n",
    "#if the single best variable isn't high in above ranking, collinearity might be an issue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notably, when we run the code for interactions and find the least squares regression for all variables including the interactions, we find that the interaction occupancy_rate x room_rate seems to be highly significant, with a close to infinite t-value and a P-value of virtually 0. Upon a closer look at the data in Excel, we find that the room receipt column is calculated by multiplying the occupancy rate by the room rate.\n",
    "\n",
    "Keeping in mind that room receipt is processed data, I have opted to conduct an analysis where the room rate, instead of room receipt, is the dependent variable. I felt that it would be counter-intuitive to attempt to train a model to predict room receipt using all other data, when it can be perfectly calcualted just by multiplying the room rate by the occupancy rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactions with room rate as Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    room_rate  Year Month Days    Type  occupancy_rate  room_receipt\n",
      "0  506.427381  2020     1   31  Luxury       83.478003    422.755465\n",
      "1  493.608149  2019    12   31  Luxury       86.472915    426.837353\n",
      "2  452.747203  2019    11   30  Luxury       89.676464    406.007682\n",
      "3  457.485963  2019    10   31  Luxury       87.985274    402.520279\n",
      "4  489.061425  2019     9   30  Luxury       88.450824    432.578859\n",
      "\n",
      " room_rate ~ occupancy_rate + room_receipt + occupancy_rate_cube + occupancy_rate_cbrt + room_receipt_cube + room_receipt_cbrt\n",
      "\n",
      "Adjusted R2 = 0.9970989996547504 for 6 Xs.\n",
      "Variable to drop: room_receipt_cube\n",
      "\n",
      "Adjusted R2 = 0.9970994018079757 for 5 Xs.\n",
      "Variable to drop: occupancy_rate_cube\n",
      "\n",
      "Adjusted R2 = 0.9970721669327363 for 4 Xs.\n",
      "Variable to drop: occupancy_rate_cbrt\n",
      "\n",
      "Adjusted R2 = 0.9969226649829774 for 3 Xs.\n",
      "Variable to drop: room_receipt_cbrt\n",
      "\n",
      "Adjusted R2 = 0.9954352780371597 for 2 Xs.\n",
      "Variable to drop: occupancy_rate\n",
      "\n",
      "Adjusted R2 = 0.9815747087177957 for 1 Xs.\n",
      "Variable left: room_receipt\n",
      "\n",
      "Restarting from best model (with 5 Xs) found so far...\n",
      "\n",
      "Adding 1 2-way interactions among 2 untransformed variables in best model found so far:\n",
      "occupancy_rate_x_room_receipt\n",
      "\n",
      "Adjusted R2 = 0.9999487465393134 for 6 Xs.\n",
      "Variable to drop: room_receipt_cbrt\n",
      "\n",
      "Adjusted R2 = 0.9999487889523228 for 5 Xs.\n",
      "Variable to drop: occupancy_rate_cbrt\n",
      "\n",
      "Adjusted R2 = 0.9999444106597666 for 4 Xs.\n",
      "Variable to drop: occupancy_rate_cube\n",
      "\n",
      "Adjusted R2 = 0.999797170037338 for 3 Xs.\n",
      "Variable to drop: occupancy_rate\n",
      "\n",
      "Adjusted R2 = 0.9997769316904033 for 2 Xs.\n",
      "Variable to drop: occupancy_rate_x_room_receipt\n",
      "\n",
      "Adjusted R2 = 0.9815747087177957 for 1 Xs.\n",
      "Variable left: room_receipt\n",
      "\n",
      "Best model has 5 Xs:\n",
      "                            Results: Ordinary least squares\n",
      "=======================================================================================\n",
      "Model:                     OLS                     Adj. R-squared:            1.000    \n",
      "Dependent Variable:        room_rate               AIC:                       1501.3226\n",
      "Date:                      2021-02-16 22:42        BIC:                       1527.5008\n",
      "No. Observations:          580                     Log-Likelihood:            -744.66  \n",
      "Df Model:                  5                       F-statistic:               2.261e+06\n",
      "Df Residuals:              574                     Prob (F-statistic):        0.00     \n",
      "R-squared:                 1.000                   Scale:                     0.77130  \n",
      "---------------------------------------------------------------------------------------\n",
      "                                Coef.    Std.Err.     t     P>|t|    [0.025     0.975] \n",
      "---------------------------------------------------------------------------------------\n",
      "Intercept                     -1267.0342 198.2129   -6.3923 0.0000 -1656.3452 -877.7231\n",
      "occupancy_rate                  -16.0634   1.9086   -8.4162 0.0000   -19.8121  -12.3147\n",
      "room_receipt                      2.4722   0.0058  424.8505 0.0000     2.4607    2.4836\n",
      "occupancy_rate_cube               0.0003   0.0000   12.0712 0.0000     0.0003    0.0004\n",
      "occupancy_rate_cbrt             555.1108  78.3795    7.0823 0.0000   401.1653  709.0564\n",
      "occupancy_rate_x_room_receipt    -0.0152   0.0001 -219.2426 0.0000    -0.0153   -0.0151\n",
      "---------------------------------------------------------------------------------------\n",
      "Omnibus:                   390.996             Durbin-Watson:                1.024     \n",
      "Prob(Omnibus):             0.000               Jarque-Bera (JB):             15324.704 \n",
      "Skew:                      2.405               Prob(JB):                     0.000     \n",
      "Kurtosis:                  27.718              Condition No.:                3479262039\n",
      "=======================================================================================\n",
      "* The condition number is large (3e+09). This might indicate             strong\n",
      "multicollinearity or other numerical problems.\n",
      "\n",
      "Descending order of X's significance:\n",
      "room_receipt\n",
      "occupancy_rate_x_room_receipt\n",
      "occupancy_rate_cube\n",
      "occupancy_rate\n",
      "occupancy_rate_cbrt\n"
     ]
    }
   ],
   "source": [
    "#interaction again but this time with y = room_rate\n",
    "df = hotel\n",
    "y = 'room_rate'\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "#get column names:\n",
    "colname = list(df)\n",
    "#move y to position 0:\n",
    "colname.insert(0, colname.pop(colname.index(y)))\n",
    "df = df[colname]\n",
    "print(df.head())\n",
    "\n",
    "#transform all Xs into cube & cube-root, using np.cbrt()\n",
    "\n",
    "trf = ['_cube', '_cbrt'] #may be adapted for square & square-root\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "for i in list(df)[1:]:\n",
    "    try:\n",
    "        df[i + trf[0]] = df[i] ** (3. if '_cube' in trf else 2.)\n",
    "        df[i + trf[1]] = np.cbrt(df[i]) if '_cube' in trf else np.sqrt(df[i])\n",
    "    except:\n",
    "        #column cannot be transformed\n",
    "        #delete non-numeric column (with no questions asked!):\n",
    "        df.drop(i, axis=1, inplace=True)\n",
    "\n",
    "#only numeric columns left\n",
    "df0 = df.copy() #kept for inclusion of interaction variables later\n",
    "    \n",
    "#perform feature selection using adjusted R2\n",
    "\n",
    "modeleq = ' + '.join(list(df)).replace('+', '~', 1)\n",
    "print('\\n',modeleq)\n",
    "maxR2 = -np.inf\n",
    "bmodeleq = modeleq\n",
    "numx = df.shape[1] - 1\n",
    "x1x2 = False #interaction variables not yet included\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "while True:\n",
    "    regout = ols(modeleq, df).fit()\n",
    "    R2 = regout.rsquared_adj\n",
    "    #see if a better model is found:\n",
    "    if R2 > maxR2:\n",
    "        maxR2 = R2\n",
    "        bmodeleq = modeleq\n",
    "#     if R2 == 0:\n",
    "#         break\n",
    "\n",
    "    print('\\nAdjusted R2 =', R2, 'for', numx, 'Xs.')\n",
    "\n",
    "    if numx == 1:\n",
    "        print('Variable left:', modeleq[modeleq.find('~') + 2 :])\n",
    "        if x1x2:\n",
    "            #one xvar left\n",
    "            #get out of 'while' loop:\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            #add interaction variables for original untransformed variables in best model so far\n",
    "            \n",
    "            numx = bmodeleq.count('+') + 1\n",
    "            print('\\nRestarting from best model (with', numx, 'Xs) found so far...')\n",
    "            \n",
    "            colname = bmodeleq.replace('~', '+').split(' + ')\n",
    "            df = df0[colname]\n",
    "            colname = colname[1:] #remove y\n",
    "            \n",
    "            for i in range(numx):\n",
    "                #look for 1st transformed variable:\n",
    "                if colname[i][-5:] in trf:\n",
    "                    i = i - 1\n",
    "                    #colname[i] is the last untransformed x\n",
    "                    break\n",
    "            \n",
    "            print('\\nAdding', int((i + 1) * i / 2), '2-way interactions among', i + 1,\n",
    "                  'untransformed variables in best model found so far:')\n",
    "            for j in range(i):\n",
    "                #untransformed x in colname up to [i]\n",
    "                for k in range(j + 1, i + 1):\n",
    "                    a = colname[j] + '_x_' + colname[k]\n",
    "                    print(a)\n",
    "                    df[a] = df[colname[j]] * df[colname[k]]\n",
    "                    \n",
    "            df0 = df.copy()\n",
    "                    \n",
    "            #delete any x too highly correlated with another x, to avoid collinearity\n",
    "            \n",
    "            corv = pd.DataFrame() #start empty dataframe for corr(Xs, y) to come\n",
    "            for x in list(df)[1:]:\n",
    "                #during 1st time thru loop, new column, with label, created in empty dataframe\n",
    "                corv.loc[x, y] = df[x].corr(df[y]) #new entry, with row label, added to dataframe\n",
    "                \n",
    "            corv = corv.loc[abs(corv).sort_values([y]).index, :] #corr(Xs, y) ranked\n",
    "            modeleq = ' + '.join(list(df0)).replace('+', '~', 1)\n",
    "            numx = df0.shape[1] - 1\n",
    "            x1x2 = True #interaction variables already included\n",
    "            \n",
    "            #beyond-pairwise collinearity may still be introduced with the interaction variables\n",
    "            \n",
    "            df = df0.copy() #ready for continuing deletion\n",
    "            continue\n",
    "\n",
    "    #identify X variable to delete by finding the one with smallest abs(t-stat):\n",
    "    t = regout.tvalues[1:]\n",
    "    xdrop = list(t[abs(t) == min(abs(t))].index)[0]\n",
    "    print('Variable to drop:', xdrop)\n",
    "    \n",
    "    df.drop(xdrop, axis=1, inplace=True)\n",
    "    modeleq = ' + '.join(list(df)).replace('+', '~', 1)\n",
    "    \n",
    "    numx = numx - 1\n",
    "\n",
    "print('\\nBest model has', bmodeleq.count('+') + 1, 'Xs:')\n",
    "out = ols(bmodeleq, df0).fit()\n",
    "#collinearity is still entirely possible at this stage\n",
    "print(out.summary2())\n",
    "\n",
    "print(\"\\nDescending order of X's significance:\")\n",
    "print('\\n'.join(list(abs(out.tvalues[1:]).sort_values(0, ascending=False).index)))\n",
    "#if the single best variable isn't high in above ranking, collinearity might be an issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our findings from the previous run of the interaction test in mind, I decided to run the code again with our new y variable set as the room rate.\n",
    "\n",
    "This time, we find that the transformed variables occupancy_rate_cube and occupancy_rate_cbrt were identified along with the interaction variable occupancy_rate_x_room_receipt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X pairs with correlations > 0.995 :\n",
      "occupancy_rate_cbrt , occupancy_rate\n",
      "\n",
      "1 variables considered for deletion:\n",
      "occupancy_rate_cbrt\n",
      "\n",
      "X pairs with correlations > 0.995 :\n",
      "(no more)\n",
      "\n",
      "1 collinear variables deleted.\n",
      "\n",
      "Adjusted R2 = 0.9999443223560164 for 5 Xs.\n",
      "Variable to drop: room_receipt_cbrt\n",
      "\n",
      "Adjusted R2 = 0.9999444106597666 for 4 Xs.\n",
      "Variable to drop: occupancy_rate_cube\n",
      "\n",
      "Adjusted R2 = 0.999797170037338 for 3 Xs.\n",
      "Variable to drop: occupancy_rate\n",
      "\n",
      "Adjusted R2 = 0.9997769316904033 for 2 Xs.\n",
      "Variable to drop: occupancy_rate_x_room_receipt\n",
      "\n",
      "Adjusted R2 = 0.9815747087177957 for 1 Xs.\n",
      "Variable left: room_receipt\n",
      "\n",
      "Best model has 4 Xs:\n",
      "                         Results: Ordinary least squares\n",
      "==================================================================================\n",
      "Model:                    OLS                   Adj. R-squared:          1.000    \n",
      "Dependent Variable:       room_rate             AIC:                     1547.9132\n",
      "Date:                     2021-02-16 22:42      BIC:                     1569.7283\n",
      "No. Observations:         580                   Log-Likelihood:          -768.96  \n",
      "Df Model:                 4                     F-statistic:             2.604e+06\n",
      "Df Residuals:             575                   Prob (F-statistic):      0.00     \n",
      "R-squared:                1.000                 Scale:                   0.83724  \n",
      "----------------------------------------------------------------------------------\n",
      "                               Coef.   Std.Err.     t     P>|t|   [0.025   0.975] \n",
      "----------------------------------------------------------------------------------\n",
      "Intercept                     136.6026   3.2731   41.7348 0.0000 130.1739 143.0313\n",
      "occupancy_rate                 -2.5524   0.0617  -41.3361 0.0000  -2.6737  -2.4311\n",
      "room_receipt                    2.4750   0.0060  409.2341 0.0000   2.4631   2.4869\n",
      "occupancy_rate_cube             0.0001   0.0000   39.0725 0.0000   0.0001   0.0001\n",
      "occupancy_rate_x_room_receipt  -0.0152   0.0001 -211.4635 0.0000  -0.0154  -0.0151\n",
      "----------------------------------------------------------------------------------\n",
      "Omnibus:                  242.987            Durbin-Watson:               1.002   \n",
      "Prob(Omnibus):            0.000              Jarque-Bera (JB):            9745.806\n",
      "Skew:                     1.122              Prob(JB):                    0.000   \n",
      "Kurtosis:                 22.956             Condition No.:               51288482\n",
      "==================================================================================\n",
      "* The condition number is large (5e+07). This might indicate             strong\n",
      "multicollinearity or other numerical problems.\n",
      "\n",
      "Descending order of X's significance:\n",
      "room_receipt\n",
      "occupancy_rate_x_room_receipt\n",
      "occupancy_rate\n",
      "occupancy_rate_cube\n",
      "    room_rate  occupancy_rate  room_receipt  occupancy_rate_cube  \\\n",
      "0  506.427381       83.478003    422.755465        581722.894680   \n",
      "1  493.608149       86.472915    426.837353        646606.835385   \n",
      "2  452.747203       89.676464    406.007682        721166.305087   \n",
      "3  457.485963       87.985274    402.520279        681129.946973   \n",
      "4  489.061425       88.450824    432.578859        691999.283188   \n",
      "\n",
      "   room_receipt_cbrt  occupancy_rate_x_room_receipt  \n",
      "0           7.505214                   35290.782085  \n",
      "1           7.529292                   36909.869974  \n",
      "2           7.404767                   36409.333330  \n",
      "3           7.383505                   35415.857068  \n",
      "4           7.562901                   38261.956388  \n"
     ]
    }
   ],
   "source": [
    "#code has been modified from Regression_ Collinearity .ipynb to use output from previous step (Interactions) as input for this step\n",
    "#delete non-numeric columns:\n",
    "df = df0.select_dtypes(['number'])\n",
    "\n",
    "#get column names:\n",
    "colname = list(df0)\n",
    "#move y to position 0:\n",
    "colname.insert(0, colname.pop(colname.index(y)))\n",
    "df = df[colname]\n",
    "\n",
    "df0 = df.copy()\n",
    "\n",
    "#delete any x too highly correlated with another x, to avoid collinearity\n",
    "\n",
    "corv = pd.DataFrame() #start empty dataframe for corr(Xs, y) to come\n",
    "for x in list(df)[1:]:\n",
    "    #during 1st time thru loop, new column, with label, created in empty dataframe\n",
    "    corv.loc[x, y] = df[x].corr(df[y]) #new entry, with row label, added to dataframe\n",
    "\n",
    "corv = corv.loc[abs(corv).sort_values([y]).index, :] #corr(Xs, y) ranked\n",
    "\n",
    "delta = 0.005 #corr difference lower limit\n",
    "dl2 = []\n",
    "icorr = True\n",
    "while icorr:\n",
    "    a = abs(corv).diff() <= delta #adjacent rows with similar abs(corr(Xs, y))\n",
    "    colname = list(df)[1:]\n",
    "    dl = []\n",
    "    print('\\nX pairs with correlations >', 1 - delta, ':')\n",
    "    for b in range(1, a.shape[0]):\n",
    "        if a.iloc[b, 0]:\n",
    "            if abs(df[a.index[b - 1]].corr(df[a.index[b]])) > 1 - delta:\n",
    "                #deleting 1 X from correlated pair:\n",
    "                dv0 = a.index[b - 1]\n",
    "                dv1 = a.index[b]\n",
    "\n",
    "                #neither should already be deleted:\n",
    "                if not (dv0 in dl) and not (dv1 in dl):\n",
    "                    #delete x with rather lower corr(x, y):\n",
    "                    if abs(corv.loc[dv0, y]) - abs(corv.loc[dv1, y]) >= delta:\n",
    "                        d = dv1\n",
    "                    elif len(dv0) < len(dv1): #delete x with longer name:\n",
    "                        d = dv1\n",
    "                    else:\n",
    "                        d = dv0\n",
    "\n",
    "                    dl.append(d) #for en masse deletion later\n",
    "                    corv.drop([d], axis=0, inplace=True) #delete from column of corr with y\n",
    "\n",
    "                    print(dv0,',',dv1)\n",
    "\n",
    "    if len(dl) > 0:\n",
    "        df.drop(axis=1, columns=dl, inplace=True) #variables deleted en masse\n",
    "        dl2 = dl2 + dl #keep for real deletion later\n",
    "        print('\\n' + str(len(dl)), 'variables considered for deletion:')\n",
    "        print('\\n'.join([str(x) for x in dl]))\n",
    "    else:\n",
    "        print('(no more)')\n",
    "        icorr = False\n",
    "\n",
    "#remaining Xs may be collinear\n",
    "print('\\n' + str(len(dl2)), 'collinear variables deleted.')\n",
    "\n",
    "#potential collinearity issues handled\n",
    "\n",
    "df0 = df.copy() #kept for inclusion of interaction variables later\n",
    "#df = df0\n",
    "    \n",
    "#perform feature selection using adjusted R2\n",
    "\n",
    "modeleq = ' + '.join(list(df)).replace('+', '~', 1)\n",
    "#print(modeleq)\n",
    "\n",
    "import numpy as np\n",
    "maxR2 = -np.inf\n",
    "bmodeleq = bmodeleq\n",
    "numx = df.shape[1] - 1\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "while True:\n",
    "    regout = ols(modeleq, df).fit()\n",
    "    R2 = regout.rsquared_adj\n",
    "    #see if a better model is found:\n",
    "    if R2 > maxR2:\n",
    "        maxR2 = R2\n",
    "        bmodeleq = modeleq\n",
    "\n",
    "    print('\\nAdjusted R2 =', R2, 'for', numx, 'Xs.')\n",
    "\n",
    "    if numx == 1:\n",
    "        print('Variable left:', modeleq[modeleq.find('~') + 2 :])\n",
    "        #one xvar left\n",
    "        #get out of 'while' loop:\n",
    "        break\n",
    "            \n",
    "    #identify X variable to delete by finding the one with smallest abs(t-stat):\n",
    "    t = regout.tvalues[1:]\n",
    "    xdrop = list(t[abs(t) == min(abs(t))].index)[0]\n",
    "    print('Variable to drop:', xdrop)\n",
    "    \n",
    "    df.drop(xdrop, axis=1, inplace=True)\n",
    "    modeleq = ' + '.join(list(df)).replace('+', '~', 1)\n",
    "    \n",
    "    numx = numx - 1\n",
    "\n",
    "print('\\nBest model has', bmodeleq.count('+') + 1, 'Xs:')\n",
    "out = ols(bmodeleq, df0).fit()\n",
    "#collinearity is still entirely possible at this stage\n",
    "print(out.summary2())\n",
    "\n",
    "print(\"\\nDescending order of X's significance:\")\n",
    "print('\\n'.join(list(abs(out.tvalues[1:]).sort_values(0, ascending=False).index)))\n",
    "#if the single best variable isn't high in above ranking, collinearity might be an issue\n",
    "print(df0.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above test found that the transformed variable occupancy_rate_cbrt and occupancy_rate have a high correlation of greater than 0.995, thus occupancy_rate_cbrt is deleted and occupancy_rate is kept instead. Other than this, there were no collinear variables with correlation beyond the threshold of 0.995."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pulling values for X and y, splitting for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occupancy_rate</th>\n",
       "      <th>room_receipt</th>\n",
       "      <th>occupancy_rate_cube</th>\n",
       "      <th>occupancy_rate_x_room_receipt</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Days</th>\n",
       "      <th>Type</th>\n",
       "      <th>room_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>67.473473</td>\n",
       "      <td>241.990349</td>\n",
       "      <td>307184.427507</td>\n",
       "      <td>16327.929269</td>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>358.645165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>80.246025</td>\n",
       "      <td>74.229698</td>\n",
       "      <td>516738.228907</td>\n",
       "      <td>5956.638251</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>Economy</td>\n",
       "      <td>92.502648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>83.199729</td>\n",
       "      <td>171.070725</td>\n",
       "      <td>575924.738253</td>\n",
       "      <td>14233.037971</td>\n",
       "      <td>2008</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>Mid-Tier</td>\n",
       "      <td>205.614523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>84.801020</td>\n",
       "      <td>142.322849</td>\n",
       "      <td>609822.193655</td>\n",
       "      <td>12069.122776</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>Mid-Tier</td>\n",
       "      <td>167.831530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>88.662429</td>\n",
       "      <td>225.627484</td>\n",
       "      <td>696977.697617</td>\n",
       "      <td>20004.680895</td>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>Upscale</td>\n",
       "      <td>254.479249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     occupancy_rate  room_receipt  occupancy_rate_cube  \\\n",
       "133       67.473473    241.990349        307184.427507   \n",
       "552       80.246025     74.229698        516738.228907   \n",
       "429       83.199729    171.070725        575924.738253   \n",
       "323       84.801020    142.322849        609822.193655   \n",
       "255       88.662429    225.627484        696977.697617   \n",
       "\n",
       "     occupancy_rate_x_room_receipt  Year Month Days      Type   room_rate  \n",
       "133                   16327.929269  2008    12   31    Luxury  358.645165  \n",
       "552                    5956.638251  2010     4   30   Economy   92.502648  \n",
       "429                   14233.037971  2008     6   30  Mid-Tier  205.614523  \n",
       "323                   12069.122776  2017     4   30  Mid-Tier  167.831530  \n",
       "255                   20004.680895  2010    11   30   Upscale  254.479249  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_df = hotel.select_dtypes(include=['category']).copy()\n",
    "#selecting only columns of the categorical type from our original dataframe\n",
    "df1 = pd.concat([df0,category_df], axis=1)\n",
    "#adding back categorical data into the output dataframe of our Interaction and Collinearity sections, since categorical data was dropped earlier in Interactions\n",
    "\n",
    "y = df1[['room_rate']]\n",
    "X = df1[['occupancy_rate','room_receipt','occupancy_rate_cube','occupancy_rate_x_room_receipt','Year','Month','Days','Type']]\n",
    "#splitting our combined dataframe into our dependent variable room rate, with all other variables as independent variables\n",
    "\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "#splitting data into test and train\n",
    "\n",
    "datatrain = pd.concat([Xtr,ytr],axis=1)\n",
    "#concatenate X train and y train into one dataframe, as statsmodels' OLS implementation takes one dataframe and one modeleq as input rather than two dataframes like scikit-learn (X and y)\n",
    "datatrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The dataset has 435 rows and 9 columns. \n",
      "\n",
      "Variable Selection using t-stat p-value & PR(>F):\n",
      "\n",
      "F-statistic = 269968.69173858303        PR(>F) = 0.0 for 8 Xs.\n",
      "Variable to drop: Year        p-value = 0.5471245722146055\n",
      "\n",
      "F-statistic = 441752.95682683616        PR(>F) = 0.0 for 7 Xs.\n",
      "Variable to drop: Type        p-value = 0.003174376103966977\n",
      "\n",
      "F-statistic = 511098.9616397614        PR(>F) = 0.0 for 6 Xs.\n",
      "Variable to drop: occupancy_rate_cube        p-value = 1.1657568688123908e-108\n",
      "\n",
      "F-statistic = 168831.50718708884        PR(>F) = 0.0 for 5 Xs.\n",
      "Variable to drop: Days        p-value = 7.909721210571235e-13\n",
      "\n",
      "F-statistic = 180691.65567120464        PR(>F) = 0.0 for 4 Xs.\n",
      "Variable to drop: Month        p-value = 5.054754939695581e-08\n",
      "\n",
      "F-statistic = 758315.0143654936        PR(>F) = 0.0 for 3 Xs.\n",
      "Variable to drop: occupancy_rate        p-value = 4.923046673013078e-12\n",
      "\n",
      "F-statistic = 1020470.1724237221        PR(>F) = 0.0 for 2 Xs.\n",
      "Variable to drop: occupancy_rate_x_room_receipt        p-value = 0.0\n",
      "\n",
      "F-statistic = 22192.90581725324        PR(>F) = 0.0 for 1 Xs.\n",
      "Variable left: room_receipt\n",
      "\n",
      "Best model equation: room_rate ~ Month + Days + Type + occupancy_rate + room_receipt + occupancy_rate_cube + occupancy_rate_x_room_receipt\n",
      "\n",
      "Minimum PR(>F) = 0.0 for 7 Xs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#modified frorm Regression_Feature_Selection.ipynb to return hout and store hout such that it is stored as a global variable and called be called upon in the following segments\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  #suppress warning messages (those with peach background)\n",
    "\n",
    "def mr(selection=False):\n",
    "    h = datatrain #use 1st column as row labels\n",
    "    #print(h.head(0)) # dataset's variable names\n",
    "    print('\\nThe dataset has', len(h), 'rows and', h.shape[1], 'columns.', '' if selection else '\\n')\n",
    "\n",
    "    \n",
    "    yvar = 'room_rate'\n",
    "    modeleq = yvar + ' ~'\n",
    "    for xvar in (  # insert new 'x variable' into a row, ending with ','\n",
    "            'Year',\n",
    "            'Month',\n",
    "            'Days',\n",
    "            'Type',\n",
    "            'occupancy_rate',\n",
    "            'room_receipt',\n",
    "            'occupancy_rate_cube',\n",
    "            'occupancy_rate_x_room_receipt'\n",
    "            ):\n",
    "        if modeleq[-1] == '~':\n",
    "            modeleq = modeleq + ' ' + xvar\n",
    "        else:\n",
    "            modeleq = modeleq + ' + ' + xvar\n",
    "\n",
    "    bmodeleq = modeleq\n",
    "    \n",
    "    if selection:\n",
    "        #eliminate X variables one by one:\n",
    "        print('\\nVariable Selection using t-stat p-value & PR(>F):')\n",
    "        \n",
    "        #initialize p-value & adjusted R2:\n",
    "        #set to infinity (or import sys; sys.maxsize) (or max=1.7976931348623157e+308 min=2.2250738585072014e-308) :\n",
    "        minfpv = np.inf #f-stat p-value\n",
    "        maxadjR2 = -minfpv\n",
    "\n",
    "        #machine learns:\n",
    "        while True:\n",
    "            hout = ols(modeleq, h).fit()\n",
    "            #print(dir(hout)) # gives all the attributes of .fit(), e.g. .fvalue & .f_pvalue\n",
    "\n",
    "            fpv = hout.f_pvalue\n",
    "            #see if a better model (smaller F-stat p-value) is found:\n",
    "            if fpv < minfpv:\n",
    "                minfpv = fpv\n",
    "                maxadjR2 = hout.rsquared_adj\n",
    "                bmodeleq = modeleq\n",
    "            elif fpv == 0.0:\n",
    "                #resolve using adjusted R2:\n",
    "                if hout.rsquared_adj >= maxadjR2:\n",
    "                    minfpv = fpv\n",
    "                    maxadjR2 = hout.rsquared_adj\n",
    "                    bmodeleq = modeleq\n",
    "                \n",
    "            numx = modeleq.count(' + ')\n",
    "            print('\\nF-statistic =', hout.fvalue, '       PR(>F) =', fpv, 'for', numx + 1, 'Xs.')\n",
    "\n",
    "            if modeleq.find(' + ') == -1:\n",
    "                # 1 xvar left\n",
    "                # adjusted-R2 for no xvar (fit is y-bar) is 0; consider if adjusted-R2 < 0 for 1 xvar\n",
    "                break\n",
    "\n",
    "            #identify X variable to delete by finding the one with largest t-stat p-value (equivalently, PR>F):\n",
    "            prf = sm.stats.anova_lm(hout, typ=2).iloc[:-1, :].sort_values(['F']\n",
    "                                ).sort_values(['df'], ascending=False)['PR(>F)']\n",
    "            maxp = max(prf)\n",
    "            #print('\\n',dict(prf))\n",
    "            xdrop = prf[maxp == prf].axes[0][0]  # 1st element of row-label .axes[0]\n",
    "\n",
    "            # xdrop removed from model equation:\n",
    "            if (modeleq.find('~ ' + xdrop + ' + ') != -1): #xdrop is 1st x\n",
    "                modeleq = modeleq.replace('~ ' + xdrop + ' + ', '~ ')\n",
    "            elif (modeleq.find('+ ' + xdrop + ' + ') != -1):\n",
    "                modeleq = modeleq.replace('+ ' + xdrop + ' + ', '+ ')\n",
    "            else: #xdrop is last x\n",
    "                modeleq = modeleq.replace(' + ' + xdrop, '')\n",
    "            #print('Model equation:',modeleq,'\\n')\n",
    "\n",
    "            #print(prf)\n",
    "            print('Variable to drop:', xdrop, '       p-value =', prf[xdrop])\n",
    "\n",
    "        #machine learnt\n",
    "        \n",
    "        print('Variable left:', prf.loc[~prf.index.isin([xdrop])].axes[0][0])\n",
    "        print('\\nBest model equation:', bmodeleq)\n",
    "        print('\\nMinimum PR(>F) =', minfpv, 'for', bmodeleq.count(' + ') + 1, 'Xs.\\n')\n",
    "\n",
    "    hout = ols(bmodeleq, h).fit()\n",
    "    return hout\n",
    "\n",
    "    #any categorical variable first, then in descending order of F-stat; but ultimately ascending order of PR(>F):\n",
    "    hlm = sm.stats.anova_lm(hout, typ=2).sort_values(['df', 'F'], ascending=False).sort_values(['PR(>F)'])\n",
    "    last = sum(hlm['df'][:-1] == 1.0)  #number of hout. bottom t-stats for numeric Xs to display with more precision\n",
    "    if len(hlm) > last + 1:\n",
    "        #print the coefficient table:\n",
    "        print(hlm.replace(np.nan, ''), '\\n')\n",
    "\n",
    "    hsum = hout.summary2()\n",
    "    #print the ANOVA table, and more:\n",
    "    print(hsum)\n",
    "\n",
    "    #construct and print the numeric variables in order of importance:\n",
    "    \n",
    "    #p-values are the same as PR(>F) from .anova_lm typ=2 & typ=3\n",
    "    print('\\n' + str(last) + (' quantitative' if len(hlm) > last + 1 else ''), \"X-coefficients' |t-stats| ranked:\")\n",
    "    nxvar = len(hout.tvalues)\n",
    "    #print(pd.concat([hout.tvalues[nxvar-last:nxvar],abs(hout.tvalues[nxvar-last:nxvar])],axis=1)\n",
    "    #      .sort_values(1, ascending=False)[0])\n",
    "    \n",
    "    c = pd.Series(hout.params[nxvar - last:nxvar].index, index=hout.params[nxvar - last:nxvar].index)\n",
    "    h2 = pd.concat([c, hout.params[nxvar - last:nxvar], hout.tvalues[nxvar - last:nxvar], hout.pvalues[nxvar - last:nxvar],\n",
    "        abs(hout.tvalues[nxvar - last:nxvar])], axis=1).sort_values(4, ascending=False).iloc[:, :-1]\n",
    "    h2.columns = ['', 'Coefficient', 't-stat', 'P>|t|']\n",
    "    h2.index = np.arange(1, len(h2) + 1)\n",
    "    print(h2)\n",
    "hout = mr(True) # do Variable Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through the variable selection process, we find that all of the variables that are still up for consideration have been chosen except for Year, due to the high p-value of 0.547 (3dp). This leaves us with a final model equation with 4 quantative variables of occupancy_rate, room_receipt, occupancy_rate_cube and occupancy_rate_x_room_receipt, as well as 3 categorical variables of Month, Days and Type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>               <td>OLS</td>         <td>Adj. R-squared:</td>     <td>1.000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>room_rate</td>           <td>AIC:</td>         <td>1133.7469</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-02-16 22:42</td>        <td>BIC:</td>         <td>1215.2538</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>         <td>435</td>         <td>Log-Likelihood:</td>    <td>-546.87</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>             <td>19</td>           <td>F-statistic:</td>     <td>4.418e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>           <td>415</td>       <td>Prob (F-statistic):</td>   <td>0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>R-squared:</td>            <td>1.000</td>            <td>Scale:</td>         <td>0.75847</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                <td></td>                 <th>Coef.</th>  <th>Std.Err.</th>     <th>t</th>      <th>P>|t|</th> <th>[0.025</th>   <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                     <td>95.3879</td>  <td>2.8230</td>   <td>33.7897</td>  <td>0.0000</td> <td>89.8388</td> <td>100.9370</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Month[T.2]</th>                    <td>34.3846</td>  <td>1.0087</td>   <td>34.0896</td>  <td>0.0000</td> <td>32.4019</td>  <td>36.3673</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Month[T.3]</th>                    <td>0.0913</td>   <td>0.2008</td>   <td>0.4546</td>   <td>0.6497</td> <td>-0.3035</td>  <td>0.4860</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Month[T.4]</th>                    <td>6.7528</td>   <td>0.2372</td>   <td>28.4673</td>  <td>0.0000</td> <td>6.2865</td>   <td>7.2191</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Month[T.5]</th>                    <td>0.0849</td>   <td>0.2005</td>   <td>0.4234</td>   <td>0.6722</td> <td>-0.3092</td>  <td>0.4790</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Month[T.6]</th>                    <td>6.6863</td>   <td>0.2383</td>   <td>28.0526</td>  <td>0.0000</td> <td>6.2177</td>   <td>7.1548</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Month[T.7]</th>                    <td>-0.0009</td>  <td>0.2328</td>   <td>-0.0037</td>  <td>0.9970</td> <td>-0.4584</td>  <td>0.4567</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Month[T.8]</th>                    <td>0.1434</td>   <td>0.2173</td>   <td>0.6597</td>   <td>0.5098</td> <td>-0.2839</td>  <td>0.5706</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Month[T.9]</th>                    <td>6.9597</td>   <td>0.2405</td>   <td>28.9414</td>  <td>0.0000</td> <td>6.4870</td>   <td>7.4324</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Month[T.10]</th>                   <td>0.0983</td>   <td>0.2094</td>   <td>0.4694</td>   <td>0.6390</td> <td>-0.3133</td>  <td>0.5098</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Month[T.11]</th>                   <td>6.7575</td>   <td>0.2460</td>   <td>27.4746</td>  <td>0.0000</td> <td>6.2741</td>   <td>7.2410</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Month[T.12]</th>                   <td>0.3094</td>   <td>0.1965</td>   <td>1.5747</td>   <td>0.1161</td> <td>-0.0768</td>  <td>0.6957</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Days[T.29]</th>                    <td>-0.3429</td>  <td>0.3210</td>   <td>-1.0682</td>  <td>0.2861</td> <td>-0.9738</td>  <td>0.2881</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Days[T.30]</th>                    <td>27.1563</td>  <td>0.8126</td>   <td>33.4183</td>  <td>0.0000</td> <td>25.5589</td>  <td>28.7536</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Days[T.31]</th>                    <td>33.8470</td>  <td>1.0172</td>   <td>33.2761</td>  <td>0.0000</td> <td>31.8476</td>  <td>35.8465</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Type[T.Luxury]</th>                <td>1.9904</td>   <td>0.5917</td>   <td>3.3640</td>   <td>0.0008</td> <td>0.8273</td>   <td>3.1534</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Type[T.Mid-Tier]</th>              <td>0.2358</td>   <td>0.1779</td>   <td>1.3255</td>   <td>0.1857</td> <td>-0.1139</td>  <td>0.5856</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Type[T.Upscale]</th>               <td>0.8475</td>   <td>0.3029</td>   <td>2.7977</td>   <td>0.0054</td> <td>0.2520</td>   <td>1.4429</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>occupancy_rate</th>                <td>-2.4219</td>  <td>0.0741</td>  <td>-32.6829</td>  <td>0.0000</td> <td>-2.5676</td>  <td>-2.2762</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>room_receipt</th>                  <td>2.4643</td>   <td>0.0097</td>  <td>254.6241</td>  <td>0.0000</td> <td>2.4453</td>   <td>2.4833</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>occupancy_rate_cube</th>           <td>0.0001</td>   <td>0.0000</td>   <td>30.0827</td>  <td>0.0000</td> <td>0.0001</td>   <td>0.0001</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>occupancy_rate_x_room_receipt</th> <td>-0.0152</td>  <td>0.0001</td>  <td>-150.8795</td> <td>0.0000</td> <td>-0.0154</td>  <td>-0.0150</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td>Omnibus:</td>    <td>140.505</td>  <td>Durbin-Watson:</td>            <td>1.928</td>        \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Prob(Omnibus):</td>  <td>0.000</td>  <td>Jarque-Bera (JB):</td>        <td>2766.347</td>       \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Skew:</td>      <td>0.853</td>      <td>Prob(JB):</td>              <td>0.000</td>        \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Kurtosis:</td>   <td>15.236</td>   <td>Condition No.:</td>   <td>6475188883356028764160</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                        Results: Ordinary least squares\n",
       "================================================================================\n",
       "Model:                    OLS                  Adj. R-squared:         1.000    \n",
       "Dependent Variable:       room_rate            AIC:                    1133.7469\n",
       "Date:                     2021-02-16 22:42     BIC:                    1215.2538\n",
       "No. Observations:         435                  Log-Likelihood:         -546.87  \n",
       "Df Model:                 19                   F-statistic:            4.418e+05\n",
       "Df Residuals:             415                  Prob (F-statistic):     0.00     \n",
       "R-squared:                1.000                Scale:                  0.75847  \n",
       "--------------------------------------------------------------------------------\n",
       "                               Coef.  Std.Err.     t     P>|t|   [0.025  0.975] \n",
       "--------------------------------------------------------------------------------\n",
       "Intercept                     95.3879   2.8230   33.7897 0.0000 89.8388 100.9370\n",
       "Month[T.2]                    34.3846   1.0087   34.0896 0.0000 32.4019  36.3673\n",
       "Month[T.3]                     0.0913   0.2008    0.4546 0.6497 -0.3035   0.4860\n",
       "Month[T.4]                     6.7528   0.2372   28.4673 0.0000  6.2865   7.2191\n",
       "Month[T.5]                     0.0849   0.2005    0.4234 0.6722 -0.3092   0.4790\n",
       "Month[T.6]                     6.6863   0.2383   28.0526 0.0000  6.2177   7.1548\n",
       "Month[T.7]                    -0.0009   0.2328   -0.0037 0.9970 -0.4584   0.4567\n",
       "Month[T.8]                     0.1434   0.2173    0.6597 0.5098 -0.2839   0.5706\n",
       "Month[T.9]                     6.9597   0.2405   28.9414 0.0000  6.4870   7.4324\n",
       "Month[T.10]                    0.0983   0.2094    0.4694 0.6390 -0.3133   0.5098\n",
       "Month[T.11]                    6.7575   0.2460   27.4746 0.0000  6.2741   7.2410\n",
       "Month[T.12]                    0.3094   0.1965    1.5747 0.1161 -0.0768   0.6957\n",
       "Days[T.29]                    -0.3429   0.3210   -1.0682 0.2861 -0.9738   0.2881\n",
       "Days[T.30]                    27.1563   0.8126   33.4183 0.0000 25.5589  28.7536\n",
       "Days[T.31]                    33.8470   1.0172   33.2761 0.0000 31.8476  35.8465\n",
       "Type[T.Luxury]                 1.9904   0.5917    3.3640 0.0008  0.8273   3.1534\n",
       "Type[T.Mid-Tier]               0.2358   0.1779    1.3255 0.1857 -0.1139   0.5856\n",
       "Type[T.Upscale]                0.8475   0.3029    2.7977 0.0054  0.2520   1.4429\n",
       "occupancy_rate                -2.4219   0.0741  -32.6829 0.0000 -2.5676  -2.2762\n",
       "room_receipt                   2.4643   0.0097  254.6241 0.0000  2.4453   2.4833\n",
       "occupancy_rate_cube            0.0001   0.0000   30.0827 0.0000  0.0001   0.0001\n",
       "occupancy_rate_x_room_receipt -0.0152   0.0001 -150.8795 0.0000 -0.0154  -0.0150\n",
       "--------------------------------------------------------------------------------\n",
       "Omnibus:              140.505      Durbin-Watson:         1.928                 \n",
       "Prob(Omnibus):        0.000        Jarque-Bera (JB):      2766.347              \n",
       "Skew:                 0.853        Prob(JB):              0.000                 \n",
       "Kurtosis:             15.236       Condition No.:         6475188883356028764160\n",
       "================================================================================\n",
       "* The condition number is large (6e+21). This might indicate             strong\n",
       "multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = hout.predict(Xte)\n",
    "#finding predicted room rate based on our x test data\n",
    "hout.summary2()\n",
    "#summary of our model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting predictions against actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ8AAAEWCAYAAAB49hJtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAr/UlEQVR4nO2de5xVZb3/3x+GQZBBBhU5CCKaZGElJr+8YB3QPJplXsLEo728ezp5ykuZUGR6kqQ4IZbZSYX0hDghyYh5IUKmK2gSIAKRN0QGRUFGwLg58/39sZ7Bxczee9bM7Nvs+b5fr/3aaz3rWWt91t57PvNcv4/MDMdxnNbSpdACHMfpmLh5OI7TJtw8HMdpE24ejuO0CTcPx3HahJuH4zhtws0jj0i6T9KtYfuTklbn6b4m6Yh83KuQSLpZ0vRC6+gsuHk0QdIaSdslbZO0QdIvJFVk+z5m9kczOzKBnksk/Snb9y8GSvnZsk34XX660DriuHmk5kwzqwA+Dvw/YHzTDJK65l2VkzWK6fsrJi2twc0jA2ZWCzwBfAT2FP+vlvQC8EJI+5ykpZLqJP1F0scaz5d0jKS/Sdoq6VdA99ixkZLWxfYPkfSwpLckbZJ0p6QPA/8LnBBKQnUh7z6S/kfS2lA6+l9JPWLXukHS65LWS7os3fNJGiPp2SZp10maE7bPkLQy6K+V9I001/mApKeC7o2SHpBU2cZnq5F0RezcvUonku6Q9JqkLZIWS/pkuudronGkpHWSbpT0BvCL8DlOCZ/T+rC9T+ycKyW9KOltSXMkHRw7ZpK+IumF8Pl8L3wOC4O2mZK6pdFyiaQ/S7pd0tvAzZk+Q0m/BAYBj4bP6psh/fjwm6uTtEzSyCSfRdYwM3/FXsAa4NNh+xBgBfC9sG/APGB/oAdRyeRN4DigDLg4nL8P0A14FbgOKAdGA7uBW8O1RgLrwnYZsAy4HehJZDInhWOXAH9qonEKMCfo6AU8CtwWjp0ObCAyvJ7AjKD7iBTPui+wFRgSS/srMCZsvw58Mmz3AT6e5jM7Ajg1PHdf4A/AlDY+Ww1wRWx/rzzARcABQFfg68AbQPdw7GZgehqNI4H3gB8EnT2A/wYWAQcF3X+JfdcnAxvDd7wP8BPgD7HrWfgO9gOOAnYC84HDgd7ASuDiNFouCVq+Gp6jR6bPsOnvMuwPADYBZxAVAk4N+33z9rdS6D/WYnuFL2kbUEf0x38X0CP2gzk5lvdnjT+2WNpq4F+BTwHrAcWO/YXU5nEC8BbQNc0PLf7HI+Bd4AOxtBOAV8L2NGBi7NgHSWMe4fh04KawPYTITPYN+2uB/wD2a+VneDawpLXPFtJqyGAeKa6xGTg6bN9MZvPYRTCakPYScEZs/zRgTdieCvwwdqyCyPwHx34LI2LHFwM3xvZ/FP/jT/Hca5N+hrHfZdw8bgR+2eScuaQxrFy8vNqSmrPNrNLMDjWzr5jZ9tix12LbhwJfD8XGulD0PgQ4OLxqLXyrgVfT3O8Q4FUzey+Btr5EJYbFsXs+GdIJ941rTHfPRmYAF4TtfweqzeyfYf8LRP/ZXpX0e0knpLqApIMkVYWqzRYiQzqwDc/WIpK+LmmVpHfCs/eO3asl3jKzHbH9g9n783k1pDU7ZmbbiP6zD4jl3xDb3p5iP1NDe/w7aukzTMWhwHlNfnsnAf0znJNV3DxaT9wMXgMmBKNpfO1rZg8SFfkHSFIs/6A013wNGKTUDWdNpz1vJPphHhW7Z2+LGngJ9z0kwT0b+S1woKRhRCYyY8+Nzf5qZmcRFeurgZlprnFb0PkxM9uPqGrR+NyteTaISlX7xvb/pXEjtG/cCHwR6GNmlcA7sXu1RNP7rSf6I2xkUEhrdkxST6LqUm3Ce7VWS6bPMFX+14hKHvHfXk8zm5glfS3i5tE+7gG+LOk4RfSU9FlJvYCFRPXar0nqKulc4BNprvMM0R/9xHCN7pJGhGMbgIGNjW9m1hDue7ukgwAkDZB0Wsg/E7hE0lBJ+wLfzfQAoUQwC5hE1IYyL1yzm6QLJfU2s93AFqA+zWV6Eap6kgYAN7Tl2QJLgXMl7atobMrlTe7zHqEaJOkmojaHtvIgMF5SX0kHAjcR/ceHyEQvlTQsNKJ+H3jazNa0436ZyPQZQvRZHR7bnw6cKek0SWXhcx0paWCO9DXDzaMdmNmzwJXAnUR17xeJ6rOY2S7g3LC/GTgfeDjNdeqBM4kazdYC60J+gKeIGm3fkLQxpN0Y7rUoFHF/BxwZrvUEUYPqUyHPUwkeZQbwaeChJtWLLwFrwj2+TPTfMBW3EDUsvgM8Fn/ONjzb7URtExuA+4EHYveZS9T79Q+iKsUOmhT/W8mtwLPAc8By4G8hDTObD3wH+DWR+X0AGNOOe7VE2s8wcBuR0dVJ+oaZvQacBXyLyExfIzKcvP1Na+8queM4TjK85OE4Tptw83Acp024eTiO0ybcPBzHaRMdckJOIwceeKANHjy4xXzvvvsuPXv2zL0g1+AaSlDD4sWLN5pZ32YH8jWUNRevY4891pKwYMGCRPlyiWtwDR1VA/Cs+fB0x3GyhZuH4zhtws3DcZw20aEbTFOxe/du1q1bx44d70+e7N27N6tWrSqgquxo6N69OwMHDqS8vDxLqhyn7ZSceaxbt45evXoxePBgGie0bt26lV69ehVUV3s1mBmbNm1i3bp1HHbYYVlU5jhtI6fVFkmVkmZJ+nuIwXCCpP0lzQvh2+ZJ6hPLPy6EfVsdmyXaKnbs2MEBBxywxzhKBUkccMABe5WoHKeQ5LrN4w7gSTP7EHA0sAoYC8w3syFEYdvGAkgaSjRr8SiiUHp3SSpry01LzTgaKdXncjomOTMPSfsRheKbCtEUdTOrI5pGfH/Idj9RuDVCepWZ7TSzV4imk6eLf+E4Tjv4ydM/YWnd0nZdI5dtHocTxRn4haSjiWI8XgP0M7PXAczs9caANkTh3RbFzl/H3iHfAJB0FXAVQL9+/aipqdnreO/evdm6deteafX19c3S8k22NOzYsaPZMydl27ZtbT43W7iGwmuYtW4WP33pp5x8wMkMqxnW9gulGjmWjRcwnCjq03Fh/w7ge0Bdk3ybw/tPgYti6VOBL2S6R6oRpitXrmyWtmXLlkQj6XJJtjSker6kdKRRja4hN9y+8HbjZmz0zNE2b/68ROdQgBGm64iigz8d9mcRRUraIKk/QHh/M5Y/HntzIO/Hk+xQfOc73+GOO+7Ys//tb3+bn/3sZxnPeeeddzjyyCNZvTpagfKCCy7gnnvuyalOp3MxZdEUrpt7HaOHjmbGuTPo2qV9FY+cVVvM7A1Fi/McaWargVOI1rJYSbS+ycTw/kg4ZQ4wQ9JkosjVQ4jiX7aZa5+8lqVvLKW+vp6ysja1vTZj2L8MY8rpUzLmufzyyzn33HO55ppraGhooKqqijlz5jBs2LCU+WfMmMHQoUO58847ueSSS7jmmmvYvHkzV155ZVY0O05T4ygva/9YoVyP8/gq8EAIcPsycClRI+1MSZcTxbQ8D8DMVkiaSWQu7wFXWxT/ssMxePBgDjjgAJYsWcKGDRs45phjGDRoEEuXLs143qmnnspDDz3E1VdfzbJly/Ij1il5cmEckGPzMLOlRG0fTTklTf4JwIRs3b+xhFCIQWJXXHEF9913H2+88QaXXXYZW7du5ZOfTL0yYmPJo6GhgVWrVtGjRw/efvttBg7MWyBsp0TJlXFACY4wLRbOOeccbrrpJnbv3s2MGTP45z//2WLJ4/bbb+fDH/4w3//+97nssstYuHChD0V32kwujQPcPHJGt27dGDVqFJWVlYnaW/7xj39w77338swzz9CrVy8+9alPceutt3LLLbfkQa1TauTaOMDNI2c0NDSwaNEiHnrooUT5P/jBD+41cW7y5Mm5kuaUOPkwDvAp+Tlh5cqVHHHEEZxyyikMGTKk0HKcTkS+jAO85JEThg4dyssvv1xoGU4nI5/GASVa8rASXQWvVJ/LaT/5Ng4oQfPo3r07mzZtKrk/NAvxPLp3715oKU6RUQjjgBKstgwcOJB169bx1ltv7UnbsWNHwf/osqGhMZKY4zRSKOOAEjSP8vLyZpG2ampqOOaYYwqkqHg0OKVFIY0DSrDa4jidgUIbB7h5OE6HoxiMA9w8HKdDUSzGAW4ejtNhKCbjADcPx+kQFJtxgJuH4xQ9xWgc4ObhOEVNsRoHuHk4TtFSzMYBbh6OU5QUu3GAm4fjFB0dwTjAzcNxioqOYhzg5uE4RUNHMg5w83CcoqCjGQeU4Kxax+kI1G3fzYiJT7G+bjtUPM6a+rs6lHGAm4fj5J3qJbXUbt5ObV0ZW8oeYXP9PfRqOInzD5/UYYwDclxtkbRG0nJJSyU9G9L2lzRP0gvhvU8s/zhJL0paLem0XGpznEIxae5qGswi4+h2D/vWj6DPzm9w+7yOFfc2H20eo8xsmJk1rhw3FphvZkOA+WEfSUOBMcBRwOnAXZKys8Cs4xQR6+u2s6Buzh7jOHDXDYiuURWmA1GIBtOzgPvD9v3A2bH0KjPbaWavAC8Cn8i/PMfJMRWPM3vjtL2MA+Dgyh4FFtY6lMtAwZJeATYDBvzczO6WVGdmlbE8m82sj6Q7gUVmNj2kTwWeMLNZTa55FXAVQL9+/Y6tqqpqUce2bduoqKjI1mO1CdfQeTXUbd/Nhnd2sKu+gT++8ygPvTWV4/c7kfP7Xk+ZIuPoIjGgTw8qe+SvzSPp5zBq1KjFsZrDHnLdYDrCzNZLOgiYJ+nvGfIqRVozZzOzu4G7AYYPH24jR45sUURNTQ1J8uUS19A5NYyvXs4Di9ZidGFL2aNs7jaVXg0n8Z+Dv8nPV/dkfd12Dq7swQ2nHcnZxwzIi6ZG2vs55NQ8zGx9eH9T0myiasgGSf3N7HVJ/YE3Q/Z1wCGx0wcC63Opz3FySfWS2mAc7N04uusbbN8Jfx57cqEltouctXlI6impV+M28G/A88Ac4OKQ7WLgkbA9BxgjaR9JhwFDgGdypc9xcs2kuaubGUdjG8eu+oZCy2s3uSx59ANmS2q8zwwze1LSX4GZki4H1gLnAZjZCkkzgZXAe8DVZlafQ32Ok1PW121PaRwA3co6/uDunJmHmb0MHJ0ifRNwSppzJgATcqXJcXJN9ZJaJs1dzfq67Wzt+giby5sbh4B+vTv+yn8+wtRxskT1klqun7mUBgtVlTTGceHxg6jssamwYrNAxy87OU4RUL2klmt/FTOOWFWlC10RMKCyB7efP4xbz/5ooeVmBS95OE47qV5Syw0PLQNSN44asGbiZwsrMgd4ycNx2snNc1awu8HSNo6WKqX9dI6TI+INo+m6YxtRquGPJYCbh+O0kuoltVz/q6U0jtRoqcRx4XGD8i8yD3i1xXFayQ0PJTeOi44fVDINpE3xkofjtILx1cvZHZwjk3GUl4lJo4/O+3yVfOLm4TgJufCehfz5pbeBlkscpW4c4NUWx0lEa4xjQGWPkjcOcPNwnBapXlKb2Dh6lJdxw2lHFkJm3vFqi+NkYHz1cqYvWgskK3EUIi5HoUhkHpJOAoaY2S8k9QUqQqhAxylZklZVenYrY8V/n14omQWjxWqLpO8CNwLjQlI5MD2Xohyn0IyvXp7IOLoIJpxTml2xLZGkzeMc4PPAu7AnOlivXIpynELSmqrK5C8O6zTVlKYkMY9dFkVJNtgTFcxxSpKkxlHeRUw5v/MaByQzj5mSfg5USroS+B1wb25lOU7+SWoc+5Z3YdJ5pT+OoyVabDA1s/+RdCqwBTgSuMnM5uVcmePkkcZgxZDZOLqViZXf+0yhZBYVLZqHpB+Y2Y3AvBRpjlMSZApW3EhZF/HD0c0ia3ZaklRbTk2R5tbrlBSZghVDVFX5kVdV9iJtyUPSfwJfAQ6X9FzsUC/gz7kW5jh5peJxNtenNo5SnhnbHjJVW2YATwC3ERajDmw1s7dzqspxckw8mA8Vj7Om/i56NZxEn13faBas2I0jNWnNw8zeAd4BLgAIS0Z2ByokVZjZ2vxIdJzsUrd9N+PmL2f77vqoqlJ/D70aTuLqYXfwh9V1BV0CsiORpMH0TGAycDDR0pCHAquAo3IrzXFyw4Z3drB9d5dmS0D+YXVdh18CMp8kaTC9FTge+IeZHUa0YFPiNg9JZZKWSPpN2N9f0jxJL4T3PrG84yS9KGm1pNNa+SyOk4hd9Q0pG0fX120vtLQORRLz2B1WeesiqYuZLQCGteIe1xCVVBoZC8w3syHA/LCPpKHAGKISzenAXZLKWnEfx0lL9ZJaRkx8isPGPkZN3aMpe1UOruxRYJUdiyTmUSepAvgD8ICkO4jWkm0RSQOBz7L3iNSzgPvD9v3A2bH0KjPbGWbsvgh8Isl9HCcT1UtqGffwcmrrtvNO2SM8vHFqM+PoTHE4soWiaSsZMkRzWbYTGc2FQG/ggVAaaencWUS9Nb2Ab5jZ5yTVmVllLM9mM+sj6U5gkZlND+lTgSfMbFaTa14FXAXQr1+/Y6uqqlp8yG3btlFRUdFivlziGgqnYfUbW9lV38CCujnM3jiN4/Y7kTF9r6eryjGMbmVd6Ne7O5U9yvOmqSN9F6NGjVpsZsObpmdsMA3VhkfM7NNAA++XGFpE0ueAN81ssaSRSU5JkdbM2czsbuBugOHDh9vIkS1fuqamhiT5colrKJyGS8c+xjtlj7K52zT2rR/BmL7XMeX57gh4pUAruZXCd5HRPMysXtI/JfUOXbetYQTweUlnEHXx7idpOrBBUn8ze11Sf6IeHIB1wCGx8wcC61t5T8cBMq9WXxb+TXkbR/tI0uaxA1guaaqkHze+WjrJzMaZ2UAzG0zUEPqUmV0EzAEuDtkuBh4J23OAMZL2kXQYMAR4ppXP4zjN2jg2pVit3ts42k+SMISPhVe2mEg0zf9yYC1wHoCZrZA0E1hJ1CB7tZnVZ/G+Tidh0tzV7w8Ai/WqdFU5DRa1cdx27kd9AFg7STIlP3E7R4Zr1AA1YXsT0ViRVPkmABPaez+nc5NukluDGa9M/GxU13fjaDcePd0pPdJMcvM2juzi5uGUFFMWTUk5yc3bOLKPL/rklAxTFk3hurnXMXroaKZ9/pcMrOyFiNZT8TaO7JNkYtxw4NtEE+K6Eo3HMDP7WI61OU5GUk2rHz10NDPOnUF5WTmjjx1caIklTZJqywPADcByooFijlNwxlcv54FFa98PHRim1Z9/+CTKy/I3UrQzk6Ta8paZzTGzV8zs1cZXzpU5ThoagxU3jTnaZ+c3uH3ey4WW12lIUvL4rqR7iWbA7mxMNLOHc6bKcTKQKVixT6vPH0nM41LgQ0TLTDZWWwxw83AKQqZgxd4dmz+SmMfRZuZBHJ2CkmmuSjzmqHfH5o8k5rFI0lAzW5lzNY6TgmaNo2mM48LjB3l3bB5JYh4nARdLeoWozcO7ap28ka5xND5XxYMVF4Yk5nF6zlU4ThoyNY42zlVxCkOLXbWhW7YSODO8Kr2r1skXmRpHe+cx8pfTnBbNQ9I1RAPFDgqv6ZK+mmthjgNEk9zSLAGpVLHnnLyRpNpyOXCcmb0L0SLXwELgJ7kU5nReGntWVm2tSmscAHX/3F0ghQ4kMw8B8aA89aSON+o47aYxCtiGhoczGgf4mI5Ck8Q8fgE8LWk2kWmcBUzNqSqn0zJp7uqUxiH2jobtU+wLT5JIYpMl1RB12QJcamZLcqrK6bSkq6oY0dR6X0e2eEgaDKie6PszfGatkyOmLJqStqoyoLKHryNbZLSmt+VAvLfFyRGNgXxO6P9ZDrGxexmHV1GKkyRT8ht7W75rZjcRLXp9ZW5lOZ2JeASw318+m4nnHsOAyh4eBazI8d4Wp6DEjaMxAtjZxwxws+gAJDGPabzf2wLRwtTe2+K0ibrtuxkx8am0oQOdjkNLa9V2AZ4Gfk/U2yK8t8VpI9VLaqndvJ3aujIPHVgCZGzzMLMG4Edm9jcz+7GZ3ZHUOCR1l/SMpGWSVki6JaTvL2mepBfCe5/YOeMkvShptaTT2vVkTlFRvaSWr89cRoOZhw4sEZI0mP5W0hekVs8k2AmcbGZHA8OA0yUdD4wF5pvZEKLQhmMBJA0lWtP2KKKZvHdJKmvlPZ0iZHz1cq771VLqzVhQN8dDB5YISczjeuAhYKekLZK2StrS0kkWsS3sloeXEY1QbVzC8n6iNhRCepWZ7TSzV4AXgU8kfhKnKGkaj2P2xmkeOrBEkJm1nKutF49KDouBI4CfmtmNkurMrDKWZ7OZ9ZF0J7DIzKaH9KnAE2Y2q8k1rwKuAujXr9+xVVVVLerYtm0bFRUV2XqsNtFZNax+Yyu76htYUDeH2Runcdx+JzKm7/WUKTKOLhID+vSgMo/T6zvrd9FWDaNGjVpsZsObpud0ucmwyv0wSZXAbEkfyZA9VbWombOZ2d3A3QDDhw+3kSNHtqijpqaGJPlySWfVcOnYx3in7FE2d4tKHGP6XseU57sDUCbxoy8enfdu2c76XWRbQ16WmzSzOqCGqC1jg6T+AOH9zZBtHXBI7LSBwPp86HNySJN4HI0lDkFBjMPJHjkreUjqC+w2szpJPYBPAz8A5gAXAxPD+yPhlDnADEmTgYOBIcAzudLn5Ibx1ct58OnXqDdjW9dH2FR+T5NFp9/zYMUlQlrzkLR/phPN7O0Wrt0fuD+0e3QBZprZbyQtBGZKuhxYC5wXrrdC0kxgJfAecHWo9jgdhPHVy5m+aC2wd5Tzzw78Pmvf3s36uu10K+vC7ecPc+MoATKVPBYTtTkIGARsDtuVRH/0h2W6sJk9BxyTIn0TcEqacyYAExLodoqMUyfX8MKb7wLNgxU/88pWXrrtDCDUs904SoK0bR5mdpiZHQ7MBc40swPN7ADgc/hqcU6MTMYhulKfwx49p3AkaTD9f2b2eOOOmT0B/GvuJDkdiZaMA6JeFaf0SNJgulHSeGA6UTXmImBTTlU5HYKPffdJtuyMmqXSGQfABccdku4STgcmScnjAqAvMDu8+oY0pxNz4T0LExnHRccP4tazfanjUiRJDNO3gWskVcSGmzudmKQlji7gxlHCJAlDeKKklURdqEg6WtJdOVfmFCVJjQNg8vnDCqDQyRdJqi23A6cR2jnMbBnwqVyKcoqTpFUViKorPpajtEk0PN3MXmuS5IO3OhkX3rOQP78UjQtMYhxeXSl9kvS2vCbpRMAkdQO+BqzKrSynmBhfvTyRcXQrEz8c7fNVOgtJzOPLwB3AAKLJa78FvpJLUU7x0BiPA1oucfxjwhmFkOgUiCTmcaSZXRhPkDQC+HNuJDnFxKS5q/cE8slkHFO8cbTTkaTN4ycJ05wSZH3d9kTG4VWVzkemWbUnACcCfSVdHzu0H+CxRTsLFY+zuT7NOA7B5C+6cXRWMlVbugEVIU+vWPoWYHQuRTnFwZRFU1hTf1eTeBwRPbuVMeEcX8mtM5PWPMzs98DvJd1nZq/mUZNTBMRXcjv/8EncPu9lX6He2YskDab3SjovhBIkrLNSZWa+rkqJkmoJyNHHDi60LKfISGIeBzYaB4CZbZZ0UO4kOfmmekktk+au9iUgnVaRxDwaJA0ys7UAkg4lRVRzp2NSvaSWcQ8vZ/vuel8C0mkVSbpqvw38SdIvJf0S+AMwLreynHwxae7q943Dl4B0WkGSKflPSvo4cDxRDNPrzGxjzpU5eSHdOA5fAtJpibQlD0kfCu8fJwqAvB6oBQaFNKcUaLKuii8B6SQlU8nj68CVwI9SHDPg5JwocvJGunEcPcrLuOG0Iwuszil2Mo3zuDK8j8qfHCeX1G3fzYiJTzXrVfFxHE5byDQ8/dxMJ5qZL7/QgaheUkvt5u3U1pU161UZfexgH8fhtJpMvS1nhtflwFTgwvC6lyiCekYkHSJpgaRVklZIuiak7y9pnqQXwnuf2DnjJL0oabUkH4SWRSbNXU2DmfeqOFkj06JPl5rZpUTtG0PN7Atm9gXgqITXfg/4upl9mKin5mpJQ4GxwHwzGwLMD/uEY2PC9U8H7gpLVTpZYH3ddhbUzfFeFSdrJBkkNtjMXo/tbwA+2NJJ4ZzXw/ZWSauIAgqdBYwM2e4HaoAbQ3qVme0EXpH0IvAJYGGiJ3Ga0XRBptkbp3mvipM1ZC0sBSjpTqIV6x8kKoWMAV40s68mvok0mGhw2UeAtWZWGTu22cz6hPssMrPpIX0q8ISZzWpyrauAqwD69et3bFVVVYv337ZtGxUVFUnl5oR8a/j7G1vZXd8AwIK6OczeOI3j9juRMX2vp0yRcXSRGNCnB5U98jeStDN+Fx1dw6hRoxab2fCm6UkGif2XpHN4P2L63WY2O6lASRXAr4FrzWyL0i89mOpAM2czs7uBuwGGDx9uI0eObFFDTU0NSfLlknxqGF+9nOlL3wW6hDaOqMQxpu91THm+O4KC9ap0tu+ilDUkqbYA/A3Yama/k7SvpF5mtrWlkySVExnHA7HemQ2S+pvZ65L6A2+G9HVAfF3CgUQD05xWkGnt2LJgz69M/GwBFTqlQpJFn64EZgE/D0kDgOoE54mol2aVmU2OHZoDXBy2LwYeiaWPkbSPpMOIqkrPJHgGJ3DchHktLjrtONkiyS/qaqKGy6cBzOyFhFPyRwBfApZLWhrSvgVMBGZKuhxYC5wXrrtC0kyileneA642M18fJiGnTq5hw9ZdQGbjGHJQz0JJdEqMJOax08x2NbZVSOpKgin5ZvYnUrdjAJyS5pwJwIQEmpwYH/r24+yoj76STMZRXtaFedePLJBKp9RIMiX/95K+BfSQdCrwEPBobmU5SRk89rFExnHR8YP40L/0SncZx2k1SczjRuAtYDnwH8DjwPhcinJapnpJLYPHPrZnv6Wqii//6GSbjNUWSV2A58zsI8A9+ZHktET1klqu/dXSPfstNY56VcXJBRlLHmbWACyTNChPepwETJq7es+2r+TmFIokDab9gRWSngHebUw0s8/nTJWTkdowH8VXcnMKSRLzuCXnKpxENEY5h5aNY40PBHNyTKZ4Ht2BLwNHEDWWTjWz9/IlzNmbZlHO3TicApOp5HE/sBv4I/AZYChwTT5EOXtTvaSWr89cRn2TeBxuHE4hyWQeQ83so7BnhqsPFS8A46uX88CitRiZqyo9ysu47VzvjnXyRybz2N24YWbvZZgN6+SI6iW1iYxjgMcddQpAJvM4WtKWsC2iEaZbwraZ2X45V9fJmTR3dUbjaCxtuGk4hSBT9HQPAVhg0i3IBFAmuXE4BcXnaRcZ8UWnt3Z9hM3lzY1DwI++eLQbh1NQ3DyKiGbdsWmM48LjB7lxOAXHzaOISLXo9IG7bqCrymkw8wWZnKLCzaOISNfG0WDmoQOdosPNo5ioeJzN9b7otNMxcPMoEnzRaaejkSQYkJNjpiyawnVzr2P00NFM+/wvGVjZCxEN/vLuWKdY8ZJHgYkbx4xzZ1BeVu6LTjsdAjePPFK9pJZvzlrGriYxR+PG4TgdBTePPLG+bjvfenLpnv14r0rXzV9z43A6HN7mkQeql9Sy6d1de/abdscufHlLhrMdpzhx88gDrQlW7DgdhZyZh6Rpkt6U9HwsbX9J8yS9EN77xI6Nk/SipNWSTsuVrnzSmuURHKejkcuSx33A6U3SxgLzzWwIMD/sI2koMAY4Kpxzl6QOPau36fIIC+rmuHE4JUXOzMPM/gC83ST5LKLwhoT3s2PpVWa208xeAV4kWh+3w/Kth5/bs72l7BFmb5yW1jhGfGD/fMtznHYjsxaXnW37xaXBwG/ColFIqjOzytjxzWbWR9KdwCIzmx7SpwJPmNmsFNe8CrgKoF+/fsdWVVW1qGPbtm1UVFRk4YmSs7z2HSAqcczeOI3j9juRMX2vp0x7G0d5WZe8LQNZiM/BNXR8DaNGjVpsZsObphdL2TlVjMOUrmZmdwN3AwwfPtxGjhzZ4sVrampIki+bXDL2sdDGEZU4xvS9jinPd98rz5CDeuZ1NbdCfA6uoXQ15Lu3ZYOk/gDh/c2Qvg44JJZvILA+z9qyypauezeONi1xXHT8IF8G0unQ5LvkMQe4GJgY3h+Jpc+QNBk4GBhCB4vWPr56OQ8+/Rr1ZmxLGQEsWvJmv33KeO6Wpu3IjtPxyGVX7YPAQuBISeskXU5kGqdKegE4NexjZiuAmcBK4EngajOrz5W2bDO+ejnTF63ds67KpmAcx/e+ma6KRo4KcdHxg9w4nJIhZyUPM7sgzaFT0uSfAEzIlZ5c8uDTrwHNx3Gs2biLl247A4jql/810tdVcUoHH2GaBdKt5Fafw54sxyk0xdLb0qFJ3cYRLY/gOKWKlzzayZRFU/a0cTQdAHbBcYdkONNxOjZuHu0gHsjna8f8eE/jaJmixtFbz/Y2Dqd08WpLG0kVAey2cwqtynHyh5c82kAq43CczoabRytx43CcCDePVuDG4Tjv4+aREDcOx9kbN48EuHE4TnPcPFrAjcNxUuPmkQE3DsdJj5tHGtw4HCczbh4pcONwnJZx82iCG4fjJMPNI4Ybh+Mkx80j4MbhOK3DzQM3DsdpC53ePNw4HKdtdGrzcONwnLbTac3DjcNx2kenNA83DsdpP53OPNw4HCc7dCrzcONwnOxRdOYh6XRJqyW9KGlstq7rxuE42aWoAiBLKgN+SrQU5Trgr5LmmNnK9lx31rpZ/PSln7pxOE4WKbaSxyeAF83sZTPbBVQBZ7Xngj9++sduHI6TA2RFtCSipNHA6WZ2Rdj/EnCcmf1XLM9VwFUA/fr1O7aqqirjNRduWsjc9XMZf9R4unYpXEFr27ZtVFRUFOz+rsE1tFXDqFGjFpvZ8GYHzKxoXsB5wL2x/S8BP0mX/9hjj7UkLFiwIFG+XOIaXENH1QA8ayn+/oqt2rIOiK/ROBBYXyAtjuNkoNjM46/AEEmHSeoGjAHmFFiT4zgpKKreFjN7T9J/AXOBMmCama0osCzHcVJQVOYBYGaPA48XWofjOJkptmqL4zgdBDcPx3HahJuH4zhtws3DcZw2UVQjTFuLpLeAVxNkPRDYmGM5rsE1lKqGQ82sb9PEDm0eSZH0rKUaXusaXINraLMGr7Y4jtMm3Dwcx2kTncU87i60AFxDI64hosNr6BRtHo7jZJ/OUvJwHCfLuHk4jtMmSt48chVQOcV9pkl6U9LzsbT9Jc2T9EJ47xM7Ni5oWi3ptCzc/xBJCyStkrRC0jUF0NBd0jOSlgUNt+RbQ+y6ZZKWSPpNITRIWiNpuaSlkp4tkIZKSbMk/T38Lk7IqoZUEYJK5UU0rf8l4HCgG7AMGJqje30K+DjwfCzth8DYsD0W+EHYHhq07AMcFjSWtfP+/YGPh+1ewD/CffKpQUBF2C4HngaOz6eGmJbrgRnAb/L9XYTrrgEObJKWbw33A1eE7W5AZTY15OWPuFAv4ARgbmx/HDAuh/cb3MQ8VgP9w3Z/YHUqHUTxS07IspZHiKLQF0QDsC/wN+C4fGsgikA3Hzg5Zh751pDKPPKmAdgPeIXQKZILDaVebRkAvBbbXxfS8kU/M3sdILwflA9dkgYDxxD958+rhlBdWAq8Ccwzs7xrAKYA3wQaYmn51mDAbyUtDkG7863hcOAt4Beh+navpJ7Z1FDq5qEUacXQN50zXZIqgF8D15rZlnxrMLN6MxtG9N//E5I+kk8Nkj4HvGlmi5Oekm0NgRFm9nHgM8DVkj6VZw1diarRPzOzY4B3iaopWdNQ6uZR6IDKGyT1Bwjvb+ZSl6RyIuN4wMweLoSGRsysDqgBTs+zhhHA5yWtIVr352RJ0/OsATNbH97fBGYTrUmUTw3rgHWh5Acwi8hMsqah1M2j0AGV5wAXh+2LidohGtPHSNpH0mHAEOCZ9txIkoCpwCozm1wgDX0lVYbtHsCngb/nU4OZjTOzgWY2mOj7fsrMLsqnBkk9JfVq3Ab+DXg+nxrM7A3gNUlHhqRTgJVZ1ZCtBrJifQFnEPU8vAR8O4f3eRB4HdhN5OKXAwcQNdy9EN73j+X/dtC0GvhMFu5/ElEx8zlgaXidkWcNHwOWBA3PAzeF9LxpaKJnJO83mObzczicqOdiGbCi8XeX788BGAY8G76PaqBPNjX48HTHcdpEqVdbHMfJEW4ejuO0CTcPx3HahJuH4zhtws3DcZw24eZRYkg6R5JJ+lCCvNdK2rcd97pE0p1tPb8QSDpb0tBC6ygF3DxKjwuAPxENkGqJa4kmsOUMSXlfD1lSWYbDZxPNIHXaiZtHCRHmtYwgGqA2JpZeJul/QnyJ5yR9VdLXgIOBBZIWhHzbYueMlnRf2D5T0tNhgtXvJPVrQcfNku6W9Fvg/yQdKml+uPd8SYNCvnTp90n6maL4JC9L+ldF8VJWNWpKcc81km6S9CfgPElXSvqrotgiv5a0r6QTgc8DkxTF2fhAeD0ZJrD9MUmJzQlke6Slvwr3Ai4Cpobtv/B+fI//JJrz0jXs7x/e1xCbNg5si22PBu4L2314P97tFcCPwvYlwJ0pdNwMLAZ6hP1HgYvD9mVAdQvp9xHNSxFwFrAF+CjRP7vFwLAU91wDfDO2f0Bs+1bgq7Frj44dmw8MCdvHEQ1nL/h32RFeeS9SOjnlAqLp6BD98V1AFFPj08D/mtl7AGb2diuvOxD4VZhI1Y0oTkRLzDGz7WH7BODcsP1LooA0mdIBHjUzk7Qc2GBmywEkrSCKm7I0xT1/Fdv+iKRbiQLgVBDFp9iLUFI7EXgomhoERMFwnAS4eZQIkg4gCn7zEUlGFEXNJH2T6D94knkI8TzdY9s/ASab2RxJI4lKFi3xbsL7pEvfGd4bYtuN++l+t/F73gecbWbLJF1CNM+lKV2AOotCCDitxNs8SofRwP+Z2aFmNtjMDiEqIZwE/Bb4cmPjpaT9wzlbiUIWNrJB0ocldQHOiaX3BmrD9sW0nr/wfhvMhUQNupnSs0Ev4PUQpuDCWPqeZ7Yo3skrks6DaGaypKOzqKGkcfMoHS4gihsR59fAvwP3AmuB5yQtC2kQLfrzRGODKVGwmN8ATxHNEG7kZqKi/R9p2+LMXwMulfQc8CXgmhbSs8F3iCKpzSMKC9BIFXBDaPz9AJGxXB4+lxVEbSxOAnxWreM4bcJLHo7jtAk3D8dx2oSbh+M4bcLNw3GcNuHm4ThOm3DzcBynTbh5OI7TJv4/06RASMWLcWgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pl.scatter(y=y_pred, x=yte)\n",
    "pl.title('Predicted vs actual room rate')\n",
    "pl.ylabel('Predicted room rate')\n",
    "pl.xlabel('Actual room rate')\n",
    "\n",
    "lineStart = 0\n",
    "lineEnd = 600\n",
    "pl.plot([lineStart, lineEnd], [lineStart, lineEnd], 'k-', color = 'g', label='y=x')\n",
    "pl.xlim(lineStart, lineEnd)\n",
    "pl.ylim(lineStart, lineEnd)\n",
    "pl.axis('square')\n",
    "pl.grid()\n",
    "pl.legend(loc='upper left')\n",
    "pl.rcParams[\"figure.figsize\"] = [6.000, 6.145] # for square plot\n",
    "# height for scrollable output window below program lines:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics for prediction versus testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.062148331244758\n",
      "Root Mean Squared Error: 1.030605807884255\n",
      "Normalised Root Mean Squared Error: 0.002419210418222755\n",
      "R^2: 0.9999345612517273\n",
      "MAE: 0.28979302649935335\n"
     ]
    }
   ],
   "source": [
    "print('Mean Squared Error:', metrics.mean_squared_error(yte, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(yte, y_pred)))\n",
    "print('Normalised Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(yte, y_pred))/(float(yte.max()-yte.min())))\n",
    "#normalise by dividing by range of values in yte\n",
    "\n",
    "print('R^2:', metrics.r2_score(yte, y_pred))\n",
    "print('MAE:', metrics.median_absolute_error(yte, y_pred))\n",
    "#printing various metrics for prediction versus the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ins>Findings from data</ins>\n",
    "\n",
    "When comparing y_pred with yte, our model achieved a RMSE of 1.0306, a normalised RMSE of 0.00242, a MAE of 0.290, and a very high R^2 of 0.99993. These suggest an extremely close fit between our predicted data and actual yte data. However, these values appear unusually optimistic and the same performance may not be achieved with test datasets from a different source. We also do not know how the model might perform with data from different geographies or time periods, opening our model's flexibility up to further investigation.\n",
    "\n",
    "Our regression model has a coefficient of -2.4219 for occupancy rate: as per the law of demand, quantity demanded (occupancy rate) and price (room rate) have an inverse relationship. The coefficient of 2.4643 for room receipt is intuitive as well, as it is calculated by multipling room rate and occupancy rate, where the values of occupancy rate lie within a range of roughly 60-90. Logically, Mid-Tier, Upscale and Luxury rooms have increasingly positive coefficients relative to our baseline type, Economy. We can also observe from the coefficients for Month that rates in February tend to be $34 more expensive as compared to those in January.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
