{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-18T14:57:59.442889Z","iopub.execute_input":"2022-07-18T14:57:59.443374Z","iopub.status.idle":"2022-07-18T14:57:59.488964Z","shell.execute_reply.started":"2022-07-18T14:57:59.443274Z","shell.execute_reply":"2022-07-18T14:57:59.487966Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Library\n# ====================================================\nimport os\nimport gc\nimport warnings\nwarnings.filterwarnings('ignore')\nimport random\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\nfrom tqdm.auto import tqdm\nimport itertools\nimport time\nimport joblib\nimport itertools\nfrom tqdm.auto import tqdm\nimport lightgbm as lgb\nfrom itertools import combinations\n\n# ====================================================\n# Configurations\n# ====================================================\nclass CFG:\n    input_dir = '../input/amex-compress/'\n    input_dir_model = '../input/lgbm-split4-seed42/'\n    seed = 42\n    n_folds = 5\n    target = 'target'\n\n# ====================================================\n# Seed everything\n# ====================================================\ndef seed_everything(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T14:57:59.490517Z","iopub.execute_input":"2022-07-18T14:57:59.490879Z","iopub.status.idle":"2022-07-18T14:58:01.925665Z","shell.execute_reply.started":"2022-07-18T14:57:59.490846Z","shell.execute_reply":"2022-07-18T14:58:01.924944Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Read test only\n# ====================================================\ndef read_test(x, splits):\n    test = pd.read_parquet(CFG.input_dir + 'test_fe_compress.parquet')\n    test_section = np.array_split(test,splits)[x]\n    del test\n    gc.collect()\n    return test_section\n# ====================================================\n# Read model only\n# ====================================================\ndef read_model(filename):\n    model = joblib.load(CFG.input_dir_model + filename)\n    return model\n# ====================================================\n#  Split predictions\n# ====================================================\ndef test_split(test,model):\n    # Label encode categorical features\n    cat_features = [\n        \"B_30\",\n        \"B_38\",\n        \"D_114\",\n        \"D_116\",\n        \"D_117\",\n        \"D_120\",\n        \"D_126\",\n        \"D_63\",\n        \"D_64\",\n        \"D_66\",\n        \"D_68\"\n    ]\n    cat_features = [f\"{cf}_last\" for cf in cat_features]\n    num_cols = list(test.dtypes[(test.dtypes == 'float32') | (test.dtypes == 'float64')].index)\n    num_cols = [col for col in num_cols if 'last' in col]\n    for col in num_cols:\n        test[col + '_round2'] = test[col].round(2)\n    num_cols = [col for col in test.columns if 'last' in col]\n    num_cols = [col[:-5] for col in num_cols if 'round' not in col]\n    for col in num_cols:\n        try:\n            test[f'{col}_last_mean_diff'] = test[f'{col}_last'] - test[f'{col}_mean']\n        except:\n            pass\n        \n    # Transform float64 and float32 to float16\n    num_cols = list(test.dtypes[(test.dtypes == 'float32') | (test.dtypes == 'float64')].index)\n    \n    for col in num_cols:\n        test[col] = test[col].astype(np.float16)\n    features = [col for col in test.columns if col not in ['customer_ID', CFG.target]]\n    \n    test_pred = model.predict(test[features])\n    \n    test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_pred})\n    test_df.set_index('customer_ID')\n    \n    del test, test_pred, cat_features, num_cols, features\n    gc.collect()\n\n    \n    return test_df\n\n    \n    \n# ====================================================\n#  Helper\n# ====================================================\n\ndef helper(splits):\n    model_filenames = ['lgbm_split4_seed42.pkl','lgbm_split4_seed39.pkl','lgbm_split4_seed420.pkl','lgbm_split4_seed73.pkl']\n    ensembled_pred_df = pd.DataFrame(columns = ['prediction'])\n    \n    for i in range(len(model_filenames)):\n        \n        model = read_model(model_filenames[i])\n        \n        model_pred_df = pd.DataFrame(columns = ['prediction'])\n        \n        for j in range(splits):\n            test= read_test(j, splits)\n            print(f'Predicting split {j+1} of {splits} with model {model_filenames[i]}')\n            split_output = test_split(test, model)\n            model_pred_df = pd.concat([model_pred_df, split_output], axis=0)\n            del test, split_output\n            gc.collect()\n            \n        del model\n        gc.collect()\n        model_pred_df['prediction'] = model_pred_df['prediction']/splits\n        \n        ensembled_pred_df = pd.concat([ensembled_pred_df, model_pred_df]).groupby(by='customer_ID',as_index=False).sum()\n        \n        del model_pred_df\n        gc.collect()\n        \n    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n    ensembled_pred_df.to_csv(f'./ensembled_pred_{timestr}.csv', index = False)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-07-18T14:58:01.927094Z","iopub.execute_input":"2022-07-18T14:58:01.927500Z","iopub.status.idle":"2022-07-18T14:58:01.942588Z","shell.execute_reply.started":"2022-07-18T14:58:01.927476Z","shell.execute_reply":"2022-07-18T14:58:01.941885Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"seed_everything(CFG.seed)\nhelper(5)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T14:58:01.943704Z","iopub.execute_input":"2022-07-18T14:58:01.944251Z","iopub.status.idle":"2022-07-18T15:24:54.485482Z","shell.execute_reply.started":"2022-07-18T14:58:01.944223Z","shell.execute_reply":"2022-07-18T15:24:54.481384Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = np.zeros(0)","metadata":{"execution":{"iopub.status.busy":"2022-07-16T01:00:06.606001Z","iopub.execute_input":"2022-07-16T01:00:06.606421Z","iopub.status.idle":"2022-07-16T01:00:06.612192Z","shell.execute_reply.started":"2022-07-16T01:00:06.606387Z","shell.execute_reply":"2022-07-16T01:00:06.610937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-16T01:00:08.214996Z","iopub.execute_input":"2022-07-16T01:00:08.215409Z","iopub.status.idle":"2022-07-16T01:00:08.222275Z","shell.execute_reply.started":"2022-07-16T01:00:08.215377Z","shell.execute_reply":"2022-07-16T01:00:08.221357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = np.append(x,x)","metadata":{"execution":{"iopub.status.busy":"2022-07-16T00:59:49.551946Z","iopub.execute_input":"2022-07-16T00:59:49.552942Z","iopub.status.idle":"2022-07-16T00:59:49.558587Z","shell.execute_reply.started":"2022-07-16T00:59:49.552896Z","shell.execute_reply":"2022-07-16T00:59:49.557226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-16T00:59:52.231852Z","iopub.execute_input":"2022-07-16T00:59:52.232386Z","iopub.status.idle":"2022-07-16T00:59:52.241170Z","shell.execute_reply.started":"2022-07-16T00:59:52.232339Z","shell.execute_reply":"2022-07-16T00:59:52.240030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_df_1 = pd.DataFrame([[123,0.5],[101,1]],columns = ['customer_ID','prediction'])\npred_df_2 = pd.DataFrame([[123,1],[101,0]],columns = ['customer_ID','prediction'])\npred_df_3 = pd.DataFrame([[123,1],[101,0]],columns = ['customer_ID','prediction'])","metadata":{"execution":{"iopub.status.busy":"2022-07-18T14:23:38.347923Z","iopub.execute_input":"2022-07-18T14:23:38.348485Z","iopub.status.idle":"2022-07-18T14:23:38.358705Z","shell.execute_reply.started":"2022-07-18T14:23:38.348450Z","shell.execute_reply":"2022-07-18T14:23:38.357218Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"ensembled_pred_df = pd.DataFrame(columns = ['customer_ID','prediction'])\ndfs = [pred_df_1,pred_df_2,pred_df_3]\nfor i in range(len(dfs)):\n    dfs[i]['prediction'] = dfs[i]['prediction']/len(dfs)\n    ensembled_pred_df = pd.concat([ensembled_pred_df,dfs[i]],axis=0).groupby(by='customer_ID',as_index=False).sum()","metadata":{"execution":{"iopub.status.busy":"2022-07-18T14:24:37.631027Z","iopub.execute_input":"2022-07-18T14:24:37.631498Z","iopub.status.idle":"2022-07-18T14:24:37.653743Z","shell.execute_reply.started":"2022-07-18T14:24:37.631458Z","shell.execute_reply":"2022-07-18T14:24:37.652146Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"ensembled_pred_df","metadata":{"execution":{"iopub.status.busy":"2022-07-18T14:24:38.389629Z","iopub.execute_input":"2022-07-18T14:24:38.391044Z","iopub.status.idle":"2022-07-18T14:24:38.401255Z","shell.execute_reply.started":"2022-07-18T14:24:38.390990Z","shell.execute_reply":"2022-07-18T14:24:38.400348Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}